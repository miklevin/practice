{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0718765-b219-4cbc-a151-3c11f4d00d57",
   "metadata": {},
   "source": [
    "# Let's get started\n",
    "\n",
    "First, good habits. Running `%load_ext lab_black` makes all your code format to uncompromoisingly compliant with some such-and-such. But it's pretty and works, so I use it. Most comments from here forward are Python comments in the code-blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22536e76-d050-4b05-936e-739afd6cac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5f834-a7c8-426a-a891-0293b5a7069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't need much right away.\n",
    "\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from pickle import loads, dumps\n",
    "from sqlitedict import SqliteDict as sqldict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8eb690-61ad-4805-8dc7-de075a7a87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch for the folder being created (if not already there).\n",
    "data = \"cats\"\n",
    "Path(data).mkdir(exist_ok=True)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc10a0-fcb3-49fa-8f53-66212b20e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's count from 0 to 9 in Python\n",
    "for i in range(10):\n",
    "    print(i, end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87161f32-802e-4733-8e41-16b28d4cfff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's count from 1 to 10 in Python\n",
    "for i in range(1, 11):\n",
    "    print(i, end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b28e486-d531-4c4d-8478-cf18a675b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't make things more difficult\n",
    "for i in range(10):\n",
    "    print(i + 1, end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a3baf-3146-4057-8eea-9599d962695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count to 100,000 by 1,000.\n",
    "for i in range(100000):\n",
    "    if not i % 1000:\n",
    "        print(i, end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da83b3a2-576c-4695-b34b-7e731be8607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many zeros in ten-thousand? In a thousand?\n",
    "for i in range(10**5):\n",
    "    if not i % 10**3:\n",
    "        print(i, end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d91e8a-5380-4a21-b512-7e6736ff8121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you format that with commas?\n",
    "for i in range(10**5):\n",
    "    if not i % 10**3:\n",
    "        print(f\"{i:,}\", end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23df744e-db78-4c60-baa1-b3c8cabbcc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's it like to write a million lines into a text file?\n",
    "filename = f\"{data}/text.txt\"\n",
    "with open(filename, \"wt\") as fh:\n",
    "    for i in range(1000000):\n",
    "        fh.write(f\"{i}\\n\")\n",
    "print(\"Done\")  # Fast!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d3dc6-3ea3-41fd-8775-44bf7b691dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# That was fast. How big is that file?\n",
    "bytesize = Path(filename).stat().st_size\n",
    "kilo = 1000\n",
    "print(f\"The file {filename} is {bytesize:,} Bytes.\")\n",
    "print(f\"Abbreviated to {bytesize / kilo:,.0f} Kilobytes.\")  # The :,0f formats\n",
    "print(f\"Or just {bytesize / kilo / kilo:.0f} Megs.\")\n",
    "print(\"Done\")\n",
    "# A million short lines is still several megs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eb6c17-6082-4045-a7ae-0da13271a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's it like to write 100,000 keys into a SQlite database?\n",
    "# Let's count down instead of up. Keys go up but count is down.\n",
    "filename = f\"{data}/database.db\"\n",
    "now = time()\n",
    "upto = 100000\n",
    "with sqldict(filename) as db:\n",
    "    for i in range(upto):\n",
    "        db[i] = None\n",
    "        if not i % 10000:\n",
    "            db.commit()\n",
    "            print(f\"{upto - i:,}...\", end=\" \")\n",
    "seconds = int(time() - now)\n",
    "print(f\"\\nDone ({seconds} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e3def5-6938-4488-bd55-e71327f9359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# That was fast. How big is that file?\n",
    "bytesize = Path(filename).stat().st_size\n",
    "kilo = 1000\n",
    "print(\"While you get the power of SQL ths way, you lose speed.\")\n",
    "print(f\"The file {filename} is {bytesize / kilo:,.0f} Kilobytes\")\n",
    "print(f\"Or ~{bytesize / kilo / kilo:.0f} Megs, but only has {upto:,} records.\")\n",
    "print(\"We will not go this route.\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efdf18f-7368-484c-bfaa-01fd4a9b5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many zeros in a billion?\n",
    "f\"{10**9:,} The Goose Drank Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a2d5cd-d123-49c6-b3bc-e663780eb324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many zeros in a hundred-million?\n",
    "f\"{10**8:,} Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa80cb-341a-4152-8800-57aa3c969fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's count down from a billion by hundred-millions\n",
    "hundredmillion = 10**8\n",
    "billion = 10**9\n",
    "now = time()\n",
    "modulorow = 1\n",
    "print(\"Count down with me from a billion in Python:\")\n",
    "for i in range(billion):\n",
    "    if not i % hundredmillion:\n",
    "        glimpse = int(time() - now)\n",
    "        print(f\"{modulorow}: {billion - i:,} ({glimpse} sec)...\")\n",
    "        modulorow += 1\n",
    "seconds = int(time() - now)\n",
    "print(f\"Done ({seconds} seconds)\")  # Computers are fast but not that fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d475fc4-c635-4e60-a415-c1981df408ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a hundred million keys and save them to disk.\n",
    "seen = set()\n",
    "million = 10**6\n",
    "for i in range(million):\n",
    "    seen.add(i)\n",
    "print(f\"Made {len(seen):,} keys.\")\n",
    "\n",
    "# Dump pickled set to file\n",
    "filename = f\"{data}/dumps.pkl\"\n",
    "kilo = 1000\n",
    "with open(filename, \"wb\") as fh:\n",
    "    fh.write(dumps(seen))\n",
    "print(f\"Saved {filename} to drive.\")\n",
    "\n",
    "# Report size of file\n",
    "bytesize = Path(filename).stat().st_size\n",
    "print(f\"{filename} is {bytesize / kilo:,.0f} Kilobytes\")\n",
    "\n",
    "# Load picled set out of file\"\n",
    "with open(filename, \"rb\") as fh:\n",
    "    seen = loads(fh.read())\n",
    "print(f\"Read native Python {type(seen)} back off of drive.\")\n",
    "print(\"Go this route because of how fast and awesome this is?\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d0b8c-28aa-4309-9df9-d1913dce321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So far I've used sequential numbers from 0 to a billion as keys.\n",
    "# Let's use cats as our keys instead. Load our packges and configure.\n",
    "\n",
    "from json import loads as js\n",
    "from PIL import Image\n",
    "from httpx import get\n",
    "from io import BytesIO\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "from pickle import loads, dumps\n",
    "from imagehash import phash, whash\n",
    "from IPython.display import display\n",
    "from PIL.PngImagePlugin import PngInfo\n",
    "\n",
    "# Where we save cats and generate thumbs.\n",
    "data = \"cats\"\n",
    "save_to = f\"{data}/source\"\n",
    "thumbs = f\"{data}/thumbs\"\n",
    "\n",
    "# Make those locatiosn if they don't exist.\n",
    "Path(data).mkdir(exist_ok=True)\n",
    "Path(save_to).mkdir(exist_ok=True)\n",
    "Path(thumbs).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee9bdc-9d22-4510-be47-67779f75e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download 30 cats that don't exist.\n",
    "\n",
    "# If you actually want to fetch 30 cats that don't exist again\n",
    "# then delete the contents of cats/source folder and re-run.\n",
    "# You can delete just a sinlge cat from source and watch it re-fill\n",
    "# except by doing so removes referenced data. Fetch more. Whatever.\n",
    "\n",
    "url = \"https://thiscatdoesnotexist.com/\"\n",
    "cats = 30\n",
    "for i in range(cats):\n",
    "    filename = f\"{save_to}/cat-{str(i).zfill(3)}.jpg\"\n",
    "    if not Path(filename).exists():\n",
    "        print(f\"{cats - i} Downloading: {filename}\")\n",
    "        response = get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img.save(filename)\n",
    "        sleep(1)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef72502a-ef06-4bbb-9962-ebce8fb846b2",
   "metadata": {},
   "source": [
    "# Noteworthy Stuff\n",
    "\n",
    "## Background\n",
    "\n",
    "We are gathering 30 cats that don't exist to help explore an image classification system that leverages the strength of native operating systems that let you drag thumbnail icons around.\n",
    "\n",
    "## Perceptual Image Hash Filenames\n",
    "\n",
    "Using perceptual image hashes as filenames naturally dedupes. Thumbnails are optionally sorted into ***minimum hamming distance*** groups to reduce the amount of work when the OS has to do when you're surfing and sorting hundreds of thousands of thumbnails. \n",
    "\n",
    "## Folders Classify\n",
    "\n",
    "Within the thumbs folder, it matters not where you put things. It just accumulates classifications on a directory-name basis while you move stuff around, return everything to home-folders\n",
    "\n",
    "- 64 pixels thumbnails seem just about right.\n",
    "- Meta-data is retrievably tucked into the PNG thumbnails.\n",
    "- You can add your own meta-data, preserving dates and such\n",
    "- Filenames are made from image size & perceptual hashes\n",
    "- This file-naming helps remove-duplicates as you organize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3a0e5-5c1b-42d2-8579-ed6d1c18b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate thumbnails for the source folder of cat images.\n",
    "# If you wish to see the thumbnails generate again, you have to\n",
    "# delete seencats.pkl and the contents of thumbs folder.\n",
    "\n",
    "size = 64\n",
    "\n",
    "# Load set of seen cats from pickle if exists.\n",
    "pickled_cats = f\"{data}/seencats.pkl\"\n",
    "if Path(pickled_cats).exists():\n",
    "    with open(pickled_cats, \"rb\") as fh:\n",
    "        seen = loads(fh.read())\n",
    "else:\n",
    "    seen = set()\n",
    "\n",
    "# Make thumbnails of cat pics.\n",
    "for cat in Path(save_to).glob(\"*.jpg\"):\n",
    "    img = Image.open(cat)\n",
    "    thumb = img.copy()\n",
    "    thumb.thumbnail((size, size))\n",
    "    awhash = whash(img, hash_size=8)\n",
    "    width, height = img.width, img.height\n",
    "    bands = \"\".join(img.getbands())\n",
    "    meta_data = {\n",
    "        \"filename\": cat.name,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"format\": img.format,\n",
    "        \"format_description\": img.format_description,\n",
    "        \"bands\": img.getbands(),\n",
    "        \"extremes\": img.getextrema(),\n",
    "        \"xmp\": img.getxmp(),\n",
    "    }\n",
    "    pi = PngInfo()\n",
    "    for meta in meta_data:\n",
    "        pi.add_text(meta, f\"{meta_data[meta]}\")\n",
    "    filename = f\"{width}x{height}_{awhash}_.png\"\n",
    "    if filename not in seen:\n",
    "        print(cat)\n",
    "        display(thumb)\n",
    "        seen.add(filename)\n",
    "        print(filename)\n",
    "        thumb.save(\n",
    "            f\"{thumbs}/{filename}\",\n",
    "            \"PNG\",\n",
    "            pnginfo=pi,\n",
    "            save_all=True,\n",
    "        )\n",
    "        print()\n",
    "with open(pickled_cats, \"wb\") as fh:\n",
    "    fh.write(dumps(seen))\n",
    "\n",
    "# Report size of file\n",
    "bytesize = Path(pickled_cats).stat().st_size\n",
    "print(f\"{pickled_cats} is {bytesize:,} Bytes\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0341edde-e3d4-49fa-9b7c-72a70ff80328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_name(n):\n",
    "    sizes = {\n",
    "        4: \"Ten Thousand\",\n",
    "        5: \"Hundred Thousand\",\n",
    "        6: \"Million\",\n",
    "        9: \"Billion\",\n",
    "        12: \"Trillion\",\n",
    "        15: \"Quadrillion\",\n",
    "        18: \"Quintillion\",\n",
    "        21: \"Sextillion\",\n",
    "        24: \"Septillion\",\n",
    "        27: \"Octillion\",\n",
    "        30: \"Nonillion\",\n",
    "        33: \"Decillion\",\n",
    "        36: \"Undecillion\",\n",
    "        39: \"Duodecillion\",\n",
    "        42: \"Tredecillion\",\n",
    "        45: \"Quattuordecillion\",\n",
    "        48: \"Quindecillion\",\n",
    "        51: \"Sexdecillion\",\n",
    "        54: \"Septendecillion\",\n",
    "        57: \"Octodecillion\",\n",
    "        60: \"Novemdecillion\",\n",
    "        63: \"Vigintillion\",\n",
    "    }\n",
    "    exponent = len(str(n)) - 1\n",
    "    exponent -= exponent % 3\n",
    "    size = sizes.get(exponent, \"extremely large\")\n",
    "    return size\n",
    "\n",
    "\n",
    "# Notice how some cats are more hexed than others.\n",
    "print(\"How unique can a 16-digit hexidecimal number really be?\")\n",
    "print()\n",
    "print(\"Filename_extract converted_2hex decimal big_number_name...\")\n",
    "for cat in Path(thumbs).glob(\"*.png\"):\n",
    "    name = cat.name\n",
    "    parts = name.split(\"_\")\n",
    "    whash = parts[1]\n",
    "    ahex = hex(int(whash, 16))\n",
    "    adec = int(ahex, 16)\n",
    "    word = size_name(adec)\n",
    "    print(whash, ahex, f\"{adec:,}\", word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a23f2d-d230-4707-ac91-0e80a889bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes, the meta data is still in the PNG thumnails.\n",
    "for i, cat in enumerate(Path(thumbs).glob(\"*.png\")):\n",
    "    print(cat)\n",
    "    img = Image.open(cat)\n",
    "    meta = img.text\n",
    "    for key in meta:\n",
    "        print(f\"{key}: {meta[key]}\")\n",
    "    print()\n",
    "    if i >= 2:\n",
    "        break  # Seen enough proof?\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a19532-0467-4146-8c3f-a7ac6808e533",
   "metadata": {},
   "source": [
    "# Organize by Folder to Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456ebf3-2a33-40d9-873f-7c64acf561c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is now possible to drag-copy tag, organize, classify, yadda yadda\n",
    "# and spin through it to see how cats were classified, per new folders.\n",
    "from os import scandir\n",
    "\n",
    "cdict = {}\n",
    "\n",
    "\n",
    "def find_thumbs(path):\n",
    "    global cdict\n",
    "    for entry in scandir(path):\n",
    "        if entry.is_dir(follow_symlinks=False):\n",
    "            try:\n",
    "                find_thumbs(entry.path)\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            try:\n",
    "                found = entry.stat(follow_symlinks=False)\n",
    "            except:\n",
    "                continue\n",
    "            name, path = entry.name, entry.path\n",
    "            path = path.split(\"/\")\n",
    "            path = \"/\".join(path[:-1]) + \"/\"\n",
    "            cdict[name] = path\n",
    "    return cdict\n",
    "\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e25756-b23a-4692-8e4f-3c4867e2e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"cats\"\n",
    "cdict = find_thumbs(f\"{data}/thumbs\")\n",
    "print(len(cdict))\n",
    "cdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c76b0d0-1b31-44a7-91e9-44196f91e3ee",
   "metadata": {},
   "source": [
    "# File Locations Don't Matter\n",
    "\n",
    "The first tag we apply to our images is the image resolution as it is easily extracted from filenames &#151; no matter where under the thumbnails hierarchy they reside. This code will walk the thumbs directory very fast because they're only 64x64 thumbnails. There are no hard ties to the original image. Joining data here against the original images is based on the fact that the same process on the original image will always result in the same filename. This frees us to organize using thumbnails and defer where to keep the originals or what their \"default\" organization path should be until later. We re-acquire actual hardwired file-paths with occasional scans like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cf3ee5-7e70-42cd-b9f1-5c26d8e8aa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort into folders by size.\n",
    "\n",
    "\n",
    "def classify_by_folder(path):\n",
    "    global cdict, seen, tags\n",
    "    for entry in scandir(path):\n",
    "        if entry.is_dir(follow_symlinks=False):\n",
    "            try:\n",
    "                classify_by_folder(entry.path)\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            try:\n",
    "                found = entry.stat(follow_symlinks=False)\n",
    "            except:\n",
    "                continue\n",
    "            name, path = entry.name, entry.path\n",
    "            seen.add(name)\n",
    "            path = path.split(\"/\")\n",
    "            path = \"/\".join(path[:-1]) + \"/\"\n",
    "            parts = name.split(\"_\")\n",
    "            size = parts[0]\n",
    "            if size not in seensizes:\n",
    "                Path(f\"{data}/thumbs/by_size/{size}\").mkdir(exist_ok=True, parents=True)\n",
    "                seensizes.add(size)\n",
    "                print(size)\n",
    "            # move_to = f\"{data}/thumbs/by_size/{size}\"\n",
    "            cdict[name] = path\n",
    "            classifications = path.split(\"/\")[2:-1]\n",
    "            classifications.append(size)\n",
    "            classifications = [x for x in classifications if not x.isnumeric()]\n",
    "            tuples = [(name, tag) for tag in classifications]\n",
    "            [tags.add(atuple) for atuple in tuples]\n",
    "            # print(classifications, name)\n",
    "    return cdict\n",
    "\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006bf0e8-8808-4c40-b835-d74ab06f0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = set()\n",
    "seensizes = set()\n",
    "tags = set()\n",
    "\n",
    "cdict = {}\n",
    "data = \"cats\"\n",
    "print(seen ^ cdict.keys())\n",
    "cdict = classify_by_folder(f\"{data}/thumbs\")\n",
    "print(seen ^ cdict.keys())\n",
    "\n",
    "# cdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e0a133-a06f-4d35-a90f-57ef2228382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0282dbbb-18d9-41b9-8135-16d4505bc4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6000edda-3b93-46f8-a3eb-6ca7c0000081",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799abd02-7be2-4367-8ac2-87754d38bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e268b-c75a-4419-ab59-59a11a1c4b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load set of classifications if it exists.\n",
    "tagtable = f\"{data}/tagtable.pkl\"\n",
    "\n",
    "if Path(tagtable).exists():\n",
    "    with open(tagtable, \"rb\") as fh:\n",
    "        # Add new tags to existing.\n",
    "        existing_tags = loads(fh.read())\n",
    "        [existing_tags.add(tag) for tag in tags]\n",
    "    with open(tagtable, \"wb\") as fh:\n",
    "        # Write combined tags out.\n",
    "        fh.write(dumps(existing_tags))\n",
    "else:\n",
    "    # Create new record of tags.\n",
    "    with open(tagtable, \"wb\") as fh:\n",
    "        fh.write(dumps(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a296cf-5477-4c01-a611-5338380fbd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tagtable, \"rb\") as fh:\n",
    "    existing_tags = loads(fh.read())\n",
    "existing_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a5803-8455-469e-b6ea-bebca0ac91ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the hamming distance adjacent cats.\n",
    "prior = int(\"0\", 16)\n",
    "for file in seen:\n",
    "    awhash = file.split(\"_\")[1]\n",
    "    current = int(awhash, 16)\n",
    "    diff = bin(current ^ prior).count(\"1\")\n",
    "    print(diff, end=\" \")\n",
    "    prior = int(awhash, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da47b1-4115-4bcc-b0f8-4702e5c3f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84c37ac-dfad-4557-93b8-e07cf7adf961",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamdiffs = Counter()\n",
    "catpairs = set()\n",
    "for cat1 in seen:\n",
    "    parts = cat1.split(\"_\")\n",
    "    for cat2 in seen:\n",
    "        parts = cat2.split(\"_\")\n",
    "        int1, int2 = [int(x, 16) for x in (washcat1, washcat2)]\n",
    "        if int1 != int2:\n",
    "            diff = bin(int1 ^ int2).count(\"1\")\n",
    "            append_list = [int(diff)]\n",
    "            catpairdiff = tuple(sorted([washcat1, washcat2]) + append_list)\n",
    "            hamdiffs[diff] += 1\n",
    "            catpairs.add(catpairdiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d7f8b5-6b07-4811-8531-30fdc46d129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(catpairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2b934c-4c51-45ce-b36c-d6c947896c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "catpairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d2ff9-5899-4664-96ee-0cd55d468930",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamdiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c051b8bf-9a07-40e1-80a5-ef94f05572e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = dict(sorted(hamdiffs.items(), key=lambda item: item[0], reverse=False))\n",
    "sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e503b7-bb0f-4008-9fd5-3be4d4f95cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d1cf17-2cab-4e3e-81ad-32339852103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(hamdiffs.keys(), hamdiffs.values())\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8241202-c77b-4304-ae1a-b99e6691dee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c10e6e-9216-45d0-861b-21cadbdc5393",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(catpairs, columns=[\"cat1\", \"cat2\", \"ham\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b69b3-1b69-468d-8798-67a09feee87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_hams = set()\n",
    "ham_goes = {}\n",
    "for cat in df.groupby(\"cat1\"):\n",
    "    name, dfg = cat\n",
    "    min_ham = dfg.ham.min()\n",
    "    min_ham = str(min_ham).zfill(2)\n",
    "    min_hams.add(min_ham)\n",
    "    ham_goes[name] = min_ham\n",
    "print(\"minimum hams:\", min_hams)\n",
    "print(\"total minimums:\", len(min_hams))\n",
    "ham_goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b5176-30c8-415b-8459-a4bc4bf9d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ham_goes))\n",
    "ham_goes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d717ea5f-9546-49d2-99e6-c646ad7e908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sizes = set()\n",
    "size_goes = {}\n",
    "for cat in df.groupby(\"cat1\"):\n",
    "    name, dfg = cat\n",
    "    min_size = dfg.sizediff.min()\n",
    "    min_size = str(min_size).zfill(2)\n",
    "    min_sizes.add(min_size)\n",
    "    size_goes[name] = min_size\n",
    "print(\"minimum sizes:\", min_sizes)\n",
    "print(\"total minimums:\", len(min_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26574ccc-5244-4a63-820e-c74feb13adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_same_size = all(size_goes.values())\n",
    "print(f\"Everything same size? {all_same_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bc0e6a-0023-488b-b50e-c400feee7ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e54e2-fc4d-42f0-81e4-f43a2067f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc29616a-8d74-4a42-beff-cf43bc249c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cdict(path):\n",
    "    global cdict, seen, tags\n",
    "    for entry in scandir(path):\n",
    "        if entry.is_dir(follow_symlinks=False):\n",
    "            try:\n",
    "                build_cdict(entry.path)\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            try:\n",
    "                found = entry.stat(follow_symlinks=False)\n",
    "            except:\n",
    "                continue\n",
    "            name, path = entry.name, entry.path\n",
    "            seen.add(name)\n",
    "            path = path.split(\"/\")\n",
    "            path = \"/\".join(path[:-1]) + \"/\"\n",
    "            parts = name.split(\"_\")\n",
    "            size = parts[0]\n",
    "            cdict[name] = path\n",
    "            classifications = path.split(\"/\")[2:-1]\n",
    "            classifications.append(size)\n",
    "            classifications = [x for x in classifications if not x.isnumeric()]\n",
    "            tuples = [(name, tag) for tag in classifications]\n",
    "            [tags.add(atuple) for atuple in tuples]\n",
    "            # print(classifications, name)\n",
    "    return cdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9a000d-bb2c-4846-a38d-9c9fd2b6a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move everyting into hamming folders\n",
    "\n",
    "# Update cdict with latest file locations\n",
    "seen = set()\n",
    "cdict = {}\n",
    "cdict = build_cdict(f\"{data}/thumbs\")\n",
    "sort_choice = \"by_size\"\n",
    "\n",
    "# Sort cats into minimum hamming-distance folders\n",
    "for file in cdict:\n",
    "    from_folder = cdict[file]\n",
    "    parts = file.split(\"_\")\n",
    "    whash = parts[1]\n",
    "    size = parts[0]\n",
    "    if whash in ham_goes:\n",
    "        sort_dict = {\n",
    "            \"by_ham\": f\"{data}/thumbs/by_ham/{ham_goes[whash]}\",\n",
    "            \"by_size\": f\"{data}/thumbs/by_size/{size}\",\n",
    "            \"by_hist\": f\"{data}/thumbs/by_hist/\",\n",
    "        }\n",
    "        folder = sort_dict[sort_choice]\n",
    "        to_path = Path(folder)\n",
    "        if not to_path.is_dir():\n",
    "            Path(to_path).mkdir(parents=True, exist_ok=True)\n",
    "        full_path = f\"{from_folder}{file}\"\n",
    "        if not Path(f\"{to_path}/{file}\").exists():\n",
    "            dest = shutil.move(full_path, to_path)\n",
    "            pass\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e45a849-8836-4556-a5ff-aeb26649e26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae2da0-b734-42f7-bd0e-1f8945968bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
