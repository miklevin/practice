{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0718765-b219-4cbc-a151-3c11f4d00d57",
   "metadata": {},
   "source": [
    "# Let's get started\n",
    "\n",
    "First, good habits. Running `%load_ext lab_black` makes all your code format to uncompromoisingly compliant with some such-and-such. But it's pretty and works, so I use it. Most comments from here forward are Python comments in the code-blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22536e76-d050-4b05-936e-739afd6cac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f5f834-a7c8-426a-a891-0293b5a7069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't need much right away.\n",
    "\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from pickle import loads, dumps\n",
    "from sqlitedict import SqliteDict as sqldict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8eb690-61ad-4805-8dc7-de075a7a87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch for the folder being created (if not already there).\n",
    "data = \"cats\"\n",
    "Path(data).mkdir(exist_ok=True)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc10a0-fcb3-49fa-8f53-66212b20e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's count from 0 to 9 in Python\n",
    "for i in range(10):\n",
    "    print(i, end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87161f32-802e-4733-8e41-16b28d4cfff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's count from 1 to 10 in Python\n",
    "for i in range(1, 11):\n",
    "    print(i, end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b28e486-d531-4c4d-8478-cf18a675b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't make things more difficult\n",
    "for i in range(10):\n",
    "    print(i + 1, end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a3baf-3146-4057-8eea-9599d962695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count to 100,000 by 1,000.\n",
    "for i in range(100000):\n",
    "    if not i % 1000:\n",
    "        print(i, end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da83b3a2-576c-4695-b34b-7e731be8607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many zeros in ten-thousand? In a thousand?\n",
    "for i in range(10**5):\n",
    "    if not i % 10**3:\n",
    "        print(i, end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d91e8a-5380-4a21-b512-7e6736ff8121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you format that with commas?\n",
    "for i in range(10**5):\n",
    "    if not i % 10**3:\n",
    "        print(f\"{i:,}\", end=\" \")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23df744e-db78-4c60-baa1-b3c8cabbcc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's it like to write a million lines into a text file?\n",
    "filename = f\"{data}/text.txt\"\n",
    "with open(filename, \"wt\") as fh:\n",
    "    for i in range(1000000):\n",
    "        fh.write(f\"{i}\\n\")\n",
    "print(\"Done\")  # Fast!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d3dc6-3ea3-41fd-8775-44bf7b691dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# That was fast. How big is that file?\n",
    "bytesize = Path(filename).stat().st_size\n",
    "kilo = 1000\n",
    "print(f\"The file {filename} is {bytesize:,} Bytes.\")\n",
    "print(f\"Abbreviated to {bytesize / kilo:,.0f} Kilobytes.\")  # The :,0f formats\n",
    "print(f\"Or just {bytesize / kilo / kilo:.0f} Megs.\")\n",
    "print(\"Done\")\n",
    "# A million short lines is still several megs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eb6c17-6082-4045-a7ae-0da13271a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's it like to write 100,000 keys into a SQlite database?\n",
    "# Let's count down instead of up. Keys go up but count is down.\n",
    "filename = f\"{data}/database.db\"\n",
    "now = time()\n",
    "upto = 100000\n",
    "with sqldict(filename) as db:\n",
    "    for i in range(upto):\n",
    "        db[i] = None\n",
    "        if not i % 10000:\n",
    "            db.commit()\n",
    "            print(f\"{upto - i:,}...\", end=\" \")\n",
    "seconds = int(time() - now)\n",
    "print(f\"\\nDone ({seconds} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e3def5-6938-4488-bd55-e71327f9359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# That was fast. How big is that file?\n",
    "bytesize = Path(filename).stat().st_size\n",
    "kilo = 1000\n",
    "print(\"While you get the power of SQL ths way, you lose speed.\")\n",
    "print(f\"The file {filename} is {bytesize / kilo:,.0f} Kilobytes\")\n",
    "print(f\"Or ~{bytesize / kilo / kilo:.0f} Megs, but only has {upto:,} records.\")\n",
    "print(\"We will not go this route.\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efdf18f-7368-484c-bfaa-01fd4a9b5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many zeros in a billion?\n",
    "f\"{10**9:,} The Goose Drank Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a2d5cd-d123-49c6-b3bc-e663780eb324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many zeros in a hundred-million?\n",
    "f\"{10**8:,} Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa80cb-341a-4152-8800-57aa3c969fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's count down from a billion by hundred-millions\n",
    "hundredmillion = 10**8\n",
    "billion = 10**9\n",
    "now = time()\n",
    "modulorow = 1\n",
    "print(\"Count down with me from a billion in Python:\")\n",
    "for i in range(billion):\n",
    "    if not i % hundredmillion:\n",
    "        glimpse = int(time() - now)\n",
    "        print(f\"{modulorow}: {billion - i:,} ({glimpse} sec)...\")\n",
    "        modulorow += 1\n",
    "seconds = int(time() - now)\n",
    "print(f\"Done ({seconds} seconds)\")  # Computers are fast but not that fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d475fc4-c635-4e60-a415-c1981df408ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a hundred million keys and save them to disk.\n",
    "seen = set()\n",
    "million = 10**6\n",
    "for i in range(million):\n",
    "    seen.add(i)\n",
    "print(f\"Made {len(seen):,} keys.\")\n",
    "\n",
    "# Dump pickled set to file\n",
    "filename = f\"{data}/dumps.pkl\"\n",
    "kilo = 1000\n",
    "with open(filename, \"wb\") as fh:\n",
    "    fh.write(dumps(seen))\n",
    "print(f\"Saved {filename} to drive.\")\n",
    "\n",
    "# Report size of file\n",
    "bytesize = Path(filename).stat().st_size\n",
    "print(f\"{filename} is {bytesize / kilo:,.0f} Kilobytes\")\n",
    "\n",
    "# Load picled set out of file\"\n",
    "with open(filename, \"rb\") as fh:\n",
    "    seen = loads(fh.read())\n",
    "print(f\"Read native Python {type(seen)} back off of drive.\")\n",
    "print(\"Go this route because of how fast and awesome this is?\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d0b8c-28aa-4309-9df9-d1913dce321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So far I've used sequential numbers from 0 to a billion as keys.\n",
    "# Let's use cats as our keys instead. Load our packges and configure.\n",
    "\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from httpx import get\n",
    "from io import BytesIO\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from pickle import loads, dumps\n",
    "from imagehash import phash, whash\n",
    "from IPython.display import display\n",
    "from PIL.PngImagePlugin import PngInfo\n",
    "\n",
    "# Where we save cats and generate thumbs.\n",
    "data = \"cats\"\n",
    "save_to = f\"{data}/source\"\n",
    "thumbs = f\"{data}/thumbs\"\n",
    "\n",
    "# Make those locatiosn if they don't exist.\n",
    "Path(data).mkdir(exist_ok=True)\n",
    "Path(save_to).mkdir(exist_ok=True)\n",
    "Path(thumbs).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee9bdc-9d22-4510-be47-67779f75e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download 30 cats that don't exist.\n",
    "\n",
    "# If you actually want to fetch 30 cats that don't exist again\n",
    "# then delete the contents of cats/source folder and re-run.\n",
    "# You can delete just a sinlge cat from source and watch it re-fill\n",
    "# except by doing so removes referenced data. Fetch more. Whatever.\n",
    "\n",
    "url = \"https://thiscatdoesnotexist.com/\"\n",
    "cats = 30\n",
    "for i in range(cats):\n",
    "    filename = f\"{save_to}/cat-{str(i).zfill(3)}.jpg\"\n",
    "    if not Path(filename).exists():\n",
    "        print(f\"{cats - i} Downloading: {filename}\")\n",
    "        response = get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img.save(filename)\n",
    "        sleep(1)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3a0e5-5c1b-42d2-8579-ed6d1c18b61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate thumbnails for the source folder of cat images.\n",
    "# If you wish to see the thumbnails generate again, you have to\n",
    "# delete seencats.pkl and the contents of thumbs folder.\n",
    "\n",
    "size = 64\n",
    "\n",
    "# Load set of seen cats from pickle if exists.\n",
    "pickled_cats = f\"{data}/seencats.pkl\"\n",
    "if Path(pickled_cats).exists():\n",
    "    with open(pickled_cats, \"rb\") as fh:\n",
    "        seen = loads(fh.read())\n",
    "else:\n",
    "    seen = set()\n",
    "\n",
    "# Make thumbnails of cat pics.\n",
    "for cat in Path(save_to).glob(\"*.jpg\"):\n",
    "    img = Image.open(cat)\n",
    "    thumb = img.copy()\n",
    "    thumb.thumbnail((size, size))\n",
    "    awhash = whash(img, hash_size=8)\n",
    "    width, height = img.width, img.height\n",
    "    bands = \"\".join(img.getbands())\n",
    "    meta_data = {\n",
    "        \"filename\": cat.name,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "        \"format\": img.format,\n",
    "        \"format_description\": img.format_description,\n",
    "        \"bands\": img.getbands(),\n",
    "        \"extremes\": img.getextrema(),\n",
    "        \"xmp\": img.getxmp(),\n",
    "    }\n",
    "    pi = PngInfo()\n",
    "    for meta in meta_data:\n",
    "        pi.add_text(meta, f\"{meta_data[meta]}\")\n",
    "    filename = f\"{width}x{height}_{awhash}_.png\"\n",
    "    if filename not in seen:\n",
    "        print(cat)\n",
    "        display(thumb)\n",
    "        seen.add(filename)\n",
    "        print(filename)\n",
    "        thumb.save(\n",
    "            f\"{thumbs}/{filename}\",\n",
    "            \"PNG\",\n",
    "            pnginfo=pi,\n",
    "            save_all=True,\n",
    "        )\n",
    "        print()\n",
    "with open(pickled_cats, \"wb\") as fh:\n",
    "    fh.write(dumps(seen))\n",
    "\n",
    "# Report size of file\n",
    "bytesize = Path(pickled_cats).stat().st_size\n",
    "print(f\"{pickled_cats} is {bytesize:,} Bytes\")\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0341edde-e3d4-49fa-9b7c-72a70ff80328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_name(n):\n",
    "    sizes = {\n",
    "        4: \"Ten Thousand\",\n",
    "        5: \"Hundred Thousand\",\n",
    "        6: \"Million\",\n",
    "        9: \"Billion\",\n",
    "        12: \"Trillion\",\n",
    "        15: \"Quadrillion\",\n",
    "        18: \"Quintillion\",\n",
    "        21: \"Sextillion\",\n",
    "        24: \"Septillion\",\n",
    "        27: \"Octillion\",\n",
    "        30: \"Nonillion\",\n",
    "        33: \"Decillion\",\n",
    "        36: \"Undecillion\",\n",
    "        39: \"Duodecillion\",\n",
    "        42: \"Tredecillion\",\n",
    "        45: \"Quattuordecillion\",\n",
    "        48: \"Quindecillion\",\n",
    "        51: \"Sexdecillion\",\n",
    "        54: \"Septendecillion\",\n",
    "        57: \"Octodecillion\",\n",
    "        60: \"Novemdecillion\",\n",
    "        63: \"Vigintillion\",\n",
    "    }\n",
    "    exponent = len(str(n)) - 1\n",
    "    exponent -= exponent % 3\n",
    "    size = sizes.get(exponent, \"extremely large\")\n",
    "    return size\n",
    "\n",
    "\n",
    "# Notice how some cats are more hexed than others.\n",
    "print(\"How unique can a 16-digit hexidecimal number really be?\")\n",
    "print()\n",
    "print(\"Filename_extract converted_2hex decimal big_number_name...\")\n",
    "for cat in seen:\n",
    "    parts = cat.split(\"_\")\n",
    "    whash = parts[1]\n",
    "    ahex = hex(int(whash, 16))\n",
    "    adec = int(ahex, 16)\n",
    "    word = size_name(adec)\n",
    "    print(whash, ahex, f\"{adec:,}\", word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456ebf3-2a33-40d9-873f-7c64acf561c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import scandir\n",
    "\n",
    "def build_cdict(path):\n",
    "    global sort_choice, cdict, seen, seensizes, tags\n",
    "    for entry in scandir(path):\n",
    "        if entry.is_dir(follow_symlinks=False):\n",
    "            try:\n",
    "                build_cdict(entry.path)\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            try:\n",
    "                found = entry.stat(follow_symlinks=False)\n",
    "            except:\n",
    "                continue\n",
    "            name, path = entry.name, entry.path\n",
    "            seen.add(name)\n",
    "            path = path.split(\"/\")\n",
    "            path = \"/\".join(path[:-1]) + \"/\"\n",
    "            parts = name.split(\"_\")\n",
    "            size = parts[0]\n",
    "            cdict[name] = path\n",
    "            if sort_choice == \"by_folder\":\n",
    "                classifications = path.split(\"/\")[2:-1]\n",
    "                classifications = [x for x in classifications if not x.isnumeric()]\n",
    "            elif sort_choice == \"by_size\":\n",
    "                classifications = [size]\n",
    "            else:\n",
    "                classifications = []\n",
    "            if classifications:\n",
    "                tuples = [(name, tag) for tag in classifications]\n",
    "                [tags.add(atuple) for atuple in tuples]\n",
    "            # print(classifications, name)\n",
    "    return cdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4de95f-2f54-423d-be30-334615562468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move everyting into hamming folders\n",
    "\n",
    "# Update cdict with latest file locations\n",
    "seen = set()\n",
    "seensizes = set()\n",
    "tags = set()\n",
    "cdict = {}\n",
    "ham_goes = {}\n",
    "\n",
    "# First we classify by size\n",
    "sort_choice = \"by_size\"\n",
    "cdict = build_cdict(f\"{data}/thumbs\")\n",
    "\n",
    "hamdiffs = Counter()\n",
    "catpairs = set()\n",
    "for cat1 in cdict:\n",
    "    parts1 = cat1.split(\"_\")\n",
    "    washcat1 = parts1[1]\n",
    "    for cat2 in cdict:\n",
    "        parts2 = cat2.split(\"_\")\n",
    "        washcat2 = parts2[1]\n",
    "        int1, int2 = [int(x, 16) for x in (washcat1, washcat2)]\n",
    "        if int1 != int2:\n",
    "            diff = bin(int1 ^ int2).count(\"1\")\n",
    "            append_list = [int(diff)]\n",
    "            catpairdiff = tuple(sorted([washcat1, washcat2]) + append_list)\n",
    "            hamdiffs[diff] += 1\n",
    "            catpairs.add(catpairdiff)\n",
    "sorted_dict = dict(sorted(hamdiffs.items(), key=lambda item: item[0], reverse=False))\n",
    "plt.bar(hamdiffs.keys(), hamdiffs.values())\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame(catpairs, columns=[\"cat1\", \"cat2\", \"ham\"])\n",
    "min_hams = set()\n",
    "for cat in df.groupby(\"cat1\"):\n",
    "    name, dfg = cat\n",
    "    min_ham = dfg.ham.min()\n",
    "    min_ham = str(min_ham).zfill(2)\n",
    "    min_hams.add(min_ham)\n",
    "    ham_goes[name] = min_ham\n",
    "for whash in {x.split(\"_\")[1] for x in cdict} - ham_goes.keys():\n",
    "    ham_goes[whash] = \"00\"\n",
    "print(\"minimum hams:\", min_hams)\n",
    "print(\"total minimums:\", len(min_hams))\n",
    "print(len(ham_goes))    \n",
    "\n",
    "sort_choice = \"by_ham\"\n",
    "cdict = build_cdict(f\"{data}/thumbs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f54c906-a001-41e0-bd65-c5fc903b7898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort cats into minimum hamming-distance folders\n",
    "def sort_it(by=\"\"):\n",
    "    for file in cdict:\n",
    "        from_folder = cdict[file]\n",
    "        parts = file.split(\"_\")\n",
    "        size, whash = parts[:2]\n",
    "        by_dict = {\n",
    "            \"by_ham\": ham_goes[whash],\n",
    "            \"by_size\": size,\n",
    "            \"\": \"\",\n",
    "        }\n",
    "        the_folder = by_dict[by]\n",
    "        try:\n",
    "            to_folder = Path(f\"{data}/thumbs/{by}/{the_folder}\")\n",
    "        except:\n",
    "            continue\n",
    "        if not to_folder.is_dir():\n",
    "            Path(to_folder).mkdir(parents=True, exist_ok=True)\n",
    "        full_path = f\"{from_folder}{file}\"\n",
    "        dest_file = Path(f\"{to_folder}/{file}\")\n",
    "        if not dest_file.is_file():\n",
    "            dest = shutil.move(full_path, to_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dab5e1-964e-437f-8b6a-684a8f05a443",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_choice = \"by_size\"\n",
    "cdict = build_cdict(thumbs)\n",
    "sort_it(sort_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f3b4f-1d6c-4e82-9be5-27441445144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_choice = \"by_ham\"\n",
    "cdict = build_cdict(thumbs)\n",
    "sort_it(sort_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba15c8-8500-4596-8336-f7f2d919a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_choice = \"\"\n",
    "cdict = build_cdict(thumbs)\n",
    "sort_it()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a23f2d-d230-4707-ac91-0e80a889bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes, the meta data is still in the PNG thumnails.\n",
    "for i, cat in enumerate(cdict):\n",
    "    file = f\"{cdict[cat]}{cat}\"\n",
    "    print(file)\n",
    "    img = Image.open(file)\n",
    "    meta = img.text\n",
    "    for key in meta:\n",
    "        print(f\"{key}: {meta[key]}\")\n",
    "    print()\n",
    "    if i >= 2:\n",
    "        break  # Seen enough proof?\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14463b5c-b091-469b-9756-bb8a100b4143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
